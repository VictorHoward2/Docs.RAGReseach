### Lesson 1: Distinguishing Between Pure LLM and RAG

#### 1. What are the risks of using **only pure LLM (no RAG)** chatbots?

* âŒ **Content fabrication (hallucination)**

â†’ The LLM can *arbitrarily infer* company regulations based on general data, even if those regulations **do not exist** in the PDF.

* âŒ **Lack of internal content updates**

â†’ Company regulations are **private, new, internal** documents â†’ The LLM **is not pre-trained**.

* âŒ **Vague, general answers**

â†’ For example: instead of quoting specific clauses, the LLM answers like "typically companies willâ€¦".

* âŒ **Unverifiable sources**

â†’ It's unclear which **article or page** in the PDF the answer is based on.

* âŒ **Legal/Operational Risk**

â†’ Incorrect responses to company regulations can lead to misinterpretations and violations of company policy.

#### 2. If using **RAG (Retrieval-Augmented Generation)**, what problems are solved?

* âœ… **Responses based on the correct internal PDF document**

â†’ LLMs only respond after *retrieving the relevant section* of the company regulations.

* âœ… **Significantly Reduced Hallucination**

â†’ No "fabrication," as the information is *anchored to real data*.

* âœ… **Easy Updates**

â†’ Simply replace the PDF â†’ no need to retrain LLMs.

* âœ… **Can Be Cited and Verified**

â†’ Know that the response comes from a **specific section/article** in the regulations.

* âœ… **Suitable for private/enterprise data**

â†’ Solves the right problem: *LLM doesn't know internal data, RAG supplements external memory*.

---

Below is the **solution â€“ focusing on the criterion of â€œwhether or not knowledge outside of LLM is neededâ€** ğŸ‘‡

---

### Lesson 2: Identifying whether a problem requires RAG

1. **Chatbot answering about company internal rules** â†’ âœ” **REQUIRES RAG**

* Internal rules are **private data, not included in the LLM training data**

* The answer must be **correctly worded, no speculation allowed**

2. **Writing romantic love poems** â†’ âœ˜ **DOES NOT REQUIRE RAG**

* The problem is **creative**, not dependent on specific data

* Pure LLM has done very well

3. **Questions and answers about internal technical documents** â†’ âœ” **REQUIRES RAG**

* Technical documents are often **long, detailed, and specific to the organization**

* The relevant section must be accessed before answering Words

4. **Write a creative marketing slogan** â†’ âœ˜ **NO RAG required**

* The goal is **ideas & language**, not data accuracy

* RAG does not provide clear value

---

### Lesson 3: Choosing a chunking strategy

#### 1. Why **cannot include an entire 50-page PDF file in an LLM**?

* âŒ **Exceeds context window limit**

â†’ LLMs have a limit on the number of tokens that can be entered; a 50-page PDF usually **far exceeds its capacity**.

* âŒ **Costly and slow**

â†’ Including the entire document in each question is **very token-intensive** and impractical.

* âŒ **Reduces answer quality**

â†’ Too much information â†’ LLMs **find it difficult to focus on the relevant part**, leading to rambling answers.

* âŒ **Not optimized for retrieval**

â†’ LLM does not have a â€œfind the right sectionâ€ mechanism if the document is not split.

#### 2. What **chunk size** should be in tokens? Is there an **overlap**? Why?

* âœ… **Recommended chunk size:** approximately **300â€“500 tokens**

* Long enough to **contain an entire idea/instruction**

* Not too long to compromise accuracy during retrieval

* âœ… **Overlap:** approximately **50â€“100 tokens**

* Avoid losing context when important content is **at the boundary between two chunks**

* Makes the answer more complete (e.g., definition at the end of the first chunk, example at the beginning of the second chunk)

* âŒ **Do not use chunks that are too small**

â†’ Loss of flow, disjointed answer

* âŒ **Do not use chunks that are too large**

â†’ Reduces embedding and retrieval efficiency

---

### Lesson 4: Identifying good and poor chunks

#### ğŸ”¹ A. Cut to exactly 500 tokens, regardless of semantics

* âŒ **Chunks can be cut off midway** **Points**
* âŒ **Loss of logical context** (definition in this chunk, example in another chunk)
* âŒ **Poor quality embedding** due to disorganized content
* âŒ When retrieved, LLM receives an **incomplete** section to answer

ğŸ‘‰ This method is **technically simple but poor in quality**

#### ğŸ”¹ B. Divide by document headings/sections

* âœ… **Each chunk corresponds to a complete idea**
* âœ… **Maintains context and content logic**
* âœ… **Embedding has clear meaning**
* âœ… Retrieval returns **the correct section to read**, helping LLM answer more accurately

ğŸ‘‰ This is a **meaningful chunk (semantic chunk)**

---
### Lesson 5: Understanding embedding through examples

#### Preferred chunk: **A. "Instructions for changing account password"** âœ”

#### Explanation of why **A > B**

* ğŸ” **Semantics are closer to the question**

* *reset password* â‰ˆ *change password*

* *system/account* â†’ same technical action

* ğŸ§  **Embedding encodes meaning, not just keywords**

* Although it doesn't contain the exact word "reset"

* But the **action + goal** is the same

* ğŸ“ˆ **A's embedding vector is closer to the question**

* Both talk about **the process of changing a password**

* Lie in the same â€œsemantic spaceâ€

### Why **B is not prioritized** âŒ

* "Information security regulations":

* **Policy/principle-based**

* Does not answer **specific instructions**
* Semantics are **far removed from the action of â€œresetâ€**

* Although There is an ambiguous *confidentiality* related word.

---

### Lesson 6: Too many or too few Top-K?

### 1. Why does **Top-K = 20** cause the answer to be rambling?

* âŒ **Too many chunks are included in the context**

* Not all 20 chunks are closely related

* The LLM has to â€œreadâ€ too much information

* âŒ **Semantic noise**

* Some chunks are only *slightly related*

* But still take up space in the context

* âŒ **The LLM loses focus**

* It's unclear which section is â€œmost importantâ€

* Leading to a scattered answer synthesis

* âŒ **Context dilution**

* Correct information is â€œdilutedâ€ by less relevant information

### 2. Which parameters will you adjust?

* ğŸ”§ **Reduce Top-K**

* Example: from **20 â†’ 5 or 3**

* Only keep the **most relevant** chunks

* ğŸ”§ *(Advanced Option)* **Apply score threshold**

* Only take chunks with similarity > a certain threshold

* Avoid pulling in "similar" chunks

* ğŸ”§ *(If more information is still needed)* **Re-ranking**

* Take the larger Top-K first (e.g., 20)

* Then **re-rank â†’ choose the smaller Top-N**

---

### Lesson 7: Writing a safe RAG prompt

#### Suggested Prompt

> You are an AI assistant answering questions **based only on the CONTEXT provided below**.

>
> **Required Rules:**

>
> * Only use information contained in the CONTEXT

> * No speculation, no use of external knowledge

> * If the CONTEXT **does not contain information to answer the question**, answer with a single sentence: **â€œNo information found.â€**

>
> **CONTEXT:**

> {{context}}

>
> **QUESTION:**

> {{question}}

---

### Lesson 8: Identifying Poorly RAG Prompts

#### What's wrong with the prompt?

> **â€œBased on the above document *and your knowledge*â€¦â€**

ğŸ‘‰ The phrase **â€œand your knowledgeâ€** is the most dangerous point.

#### Specific Risks

* âŒ **Allows LLMs to use knowledge outside the context**

* LLMs will mix **documents + training knowledge**

* Loss of the true nature of â€œanswers grounded on dataâ€

* âŒ **Opens the door to hallucination**

* When documents lack information â†’ LLMs **compensate with speculation**

* âŒ **Unable to distinguish information from documents**

* Answers sound â€œreasonableâ€ but **cannot be verified**

* âŒ **RAG becomes a purely disguised LLM**

* Retrieval is ineffective

* Does not guarantee the accuracy of internal data

---

### Lesson 9: When is re-ranking necessary?

#### 1. **What are the benefits of re-ranking?**

* ğŸ” **Rearranges the relevance of chunks**

* Brings **3 truly relevant chunks** to the top

* Moves similar chunks to the bottom or removes them

* ğŸ¯ **Increases context precision**

* LLM reads **less but more accurately**

* Reduces noise and rambling answers

* ğŸ§  **Better understanding of question-context relationships**

* Re-ranker (usually a cross-encoder) considers **the question + each chunk**

* More accurate than pure embedding similarity

* ğŸš« **Reduces indirect hallucination**

* Fewer incorrect contexts â†’ fewer opportunities for LLM to speculate

#### 2. **Where is re-ranking located in the pipeline?**

ğŸ‘‰ **After retrieval, before adding context to LLM**

Standard pipeline:

```
User Question

â†“
Embedding Search (Large Top-K)

â†“
Re-ranking (select the smaller, most accurate Top-N)

â†“
LLM Answer Generation
```

---

### Lesson 10: Multi-query for ambiguous questions

Original sentence: **â€œLeave Policyâ€** â†’ too short, unclear which *aspect* the user wants.

#### 3 clearer queries for document retrieval

1. **â€œRegulations on the number of annual leave days for employeesâ€**

â†’ Clarify the *type of leave* and *applicable subjects*

2. **â€œConditions and procedures for requesting leave in the companyâ€**

â†’ Focus on the *process/method of implementation*

3. **â€œPaid and unpaid leave casesâ€**

â†’ Focus on *benefits and classifications*

#### Why is multi-query effective? ğŸ§ 

* ğŸ” Covers **multiple reasonable intents** of the same question

* ğŸ“ˆ Increases **recall** when retrieving

* ğŸ¤– Helps RAG not depend on **a single way of expressing**

#### Suggested Prompt

```
You are the system supporting document retrieval for RAG.

Your task is:
- Analyze the user's question
- Generate 3â€“5 different queries, each clarifying a reasonable aspect (intent) of the question
- The queries must:

+ Maintain the original intent

+ Be clear and specific

+ Be suitable for searching within internal documentation
- Not invent new topics
- Not answer the question

USER QUESTION:

{{question}}

Return a list of queries, each on a separate line.

```

ğŸ‘‰ This prompt is usually placed **before the retrieval step**, so that the LLM acts as a â€œquery rewriterâ€.

#### Why is this prompt recommended?

* ğŸ§  **Separate ambiguous intents into multiple perspectives**
* ğŸš« Prohibit replies â†’ avoid â€œLLM always repliesâ€
* ğŸ¯ Keep queries **close to the documentation**, don't let them stray too far

#### When **multi-query is harmful because it creates interference**

Multi-query **is not always good**. Below are cases where **multi-query should NOT be used or must be strictly controlled**:

##### âŒ 1. The question is already **very specific**

Example:

> â€œProcedure for resetting the password for the admin accountâ€

ğŸ‘‰ Multi-query in this case:

* Does not increase recall
* Only creates **similar** queries
* Adds unnecessary chunks

â¡ï¸ **Does more harm than good**

##### âŒ 2. The document is too broad, with many closely related topics

Example:

* Company handbook
* Comprehensive HR policy

Multi-query can:

* Access **many different chapters**
* The context becomes **diluted**, making LLM difficult to synthesize

##### âŒ 3. There is no subsequent re-ranking step.

Multi-query â†’ multiple results â†’ if:

* All contexts are combined

* No filtering / no re-ranking

ğŸ‘‰ Result:

* Recall increases but **precision decreases significantly**

* The answer is rambling and lengthy

##### âŒ 4. The generated query is â€œover-interpretedâ€

Example question:

> â€œLeave Policyâ€

LLM generates queries:

* â€œMaternity leaveâ€

* â€œPersonal leaveâ€

* â€œLong-term sick leaveâ€

ğŸ‘‰ If the user **only asks about annual leave**
â†’ Multi-query has **gone too far from the original intent**

#### How to use multi-query correctly (best practice)

* âœ… Only use when the question is short and vague

* âœ… Limit to **3â€“5 queries**
* âœ… Combine **re-ranking**

* âœ… Or **score threshold** after retrieval

> **Multi-query increases recall, but if not controlled, it will destroy precision.**

Or to put it more concisely:

> â€œMulti-query is a double-edged sword: it saves ambiguous questions, but dilutes clear questions.â€

---