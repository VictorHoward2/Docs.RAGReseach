Phần lời giải thực hành được thiết kế dựa trên các config sau:
    LLM: local Ollama
    Model LLM: llama3.1:8b
    Model Embedder: nomic-embed-text
    Hệ điều hành: Windows
    Ngôn ngữ: Python